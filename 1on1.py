import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime
import json
import os
import google.generativeai as genai
from docx import Document
from docx.shared import Pt
from docx.oxml.ns import qn
from io import BytesIO
import re

# ë©”ì¸ ì»¨í…ì¸  ìµœëŒ€ ë„ˆë¹„ ì œí•œ (ìš°ì¸¡ ì˜ì—­)
st.markdown(
    """
    <style>
    .main .block-container {
        max-width: 800px;
        margin-left: auto;
        margin-right: auto;
        padding-left: 1rem;
        padding-right: 1rem;
    }
    
    /* ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°±, ì„±ì¥ ì½”ì¹­ í”¼ë“œë°± íƒ€ì´í‹€ í°íŠ¸ í¬ê¸° í™•ëŒ€ */
    /* Streamlit expander í—¤ë” ìŠ¤íƒ€ì¼ - ê¸°ë³¸ */
    div[data-testid="stExpander"] details summary,
    div[data-testid="stExpander"] summary,
    .streamlit-expanderHeader,
    div[data-testid="stExpander"] details summary p,
    div[data-testid="stExpander"] details summary label,
    div[data-testid="stExpander"] details summary div,
    div[data-testid="stExpander"] details summary span {
        font-size: 2.2rem !important;
        font-weight: 700 !important;
        line-height: 1.6 !important;
    }
    
    /* expander ë‚´ë¶€ í…ìŠ¤íŠ¸ ìš”ì†Œë“¤ë„ í¬ê²Œ */
    div[data-testid="stExpander"] summary * {
        font-size: 2.2rem !important;
        font-weight: 700 !important;
    }
    
    /* ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°± - íŒŒë‘ ê³„ì—´ ìƒ‰ìƒ */
    div[data-testid="stExpander"]:has(summary:contains("ì„±ê³¼")) details summary,
    div[data-testid="stExpander"]:has(summary:contains("ì„±ê³¼")) summary,
    div[data-testid="stExpander"]:has(summary:contains("ì„±ê³¼")) summary * {
        color: #1E88E5 !important; /* íŒŒë‘ìƒ‰ - ì„±ê³¼ */
    }
    
    /* ì„±ì¥ ì½”ì¹­ í”¼ë“œë°± - ì´ˆë¡ ê³„ì—´ ìƒ‰ìƒ */
    div[data-testid="stExpander"]:has(summary:contains("ì„±ì¥")) details summary,
    div[data-testid="stExpander"]:has(summary:contains("ì„±ì¥")) summary,
    div[data-testid="stExpander"]:has(summary:contains("ì„±ì¥")) summary * {
        color: #27AE60 !important; /* ì´ˆë¡ìƒ‰ - ì„±ì¥ */
    }
    </style>
    """,
    unsafe_allow_html=True
)

# JavaScriptë¡œ ìƒ‰ìƒ ì ìš© (CSS :has ì„ íƒì ë¯¸ì§€ì› ë¸Œë¼ìš°ì € ëŒ€ë¹„ ë° ë™ì  ì½˜í…ì¸  ëŒ€ì‘)
st.markdown("""
<script>
function applyExpanderColors() {
    const expanders = document.querySelectorAll('div[data-testid="stExpander"] summary');
    expanders.forEach(function(summary) {
        const text = summary.textContent || summary.innerText || '';
        if (text.includes('ì„±ê³¼')) {
            summary.style.color = '#1E88E5';
            // summary ë‚´ë¶€ì˜ ëª¨ë“  ìš”ì†Œì—ë„ ìƒ‰ìƒ ì ìš©
            const elements = summary.querySelectorAll('*');
            elements.forEach(function(el) {
                el.style.color = '#1E88E5';
            });
        } else if (text.includes('ì„±ì¥')) {
            summary.style.color = '#27AE60';
            // summary ë‚´ë¶€ì˜ ëª¨ë“  ìš”ì†Œì—ë„ ìƒ‰ìƒ ì ìš©
            const elements = summary.querySelectorAll('*');
            elements.forEach(function(el) {
                el.style.color = '#27AE60';
            });
        }
    });
}

// DOM ë¡œë“œ í›„ ì‹¤í–‰
if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', applyExpanderColors);
} else {
    applyExpanderColors();
}

// Streamlitì´ ì½˜í…ì¸ ë¥¼ ì—…ë°ì´íŠ¸í•  ë•Œë§ˆë‹¤ ì‹¤í–‰
const observer = new MutationObserver(applyExpanderColors);
observer.observe(document.body, { childList: true, subtree: true });

// ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬ (Streamlitì˜ ë™ì  ì½˜í…ì¸  ì—…ë°ì´íŠ¸ ëŒ€ì‘)
setInterval(applyExpanderColors, 500);
</script>
""", unsafe_allow_html=True)

# Google Sheets ì—°ë™ì„ ìœ„í•œ ì„¤ì •
SCOPE = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive"
]

# Gemini API í‚¤ ì„¤ì • (Streamlit secrets ì‚¬ìš©)
GEMINI_API_KEY = None
try:
    if hasattr(st, "secrets"):
        gemini_sec = st.secrets.get("gemini", {})
        GEMINI_API_KEY = gemini_sec.get("api_key")
except Exception:
    pass

if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
    except Exception:
        pass

# 1on1 ì½”ì¹­ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ IDëŠ” í•¨ìˆ˜ì—ì„œ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤ (ì•ˆì „ì„±ì„ ìœ„í•´)
def get_oneon1_spreadsheet_id():
    """1on1 ì½”ì¹­ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ IDë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        if hasattr(st, "secrets"):
            secrets_obj = getattr(st, "secrets", None)
            if secrets_obj and hasattr(secrets_obj, "get"):
                try:
                    google_sec = secrets_obj.get("google", {})
                    if google_sec and isinstance(google_sec, dict):
                        spreadsheet_id = google_sec.get("oneon1_spreadsheet_id")
                        if spreadsheet_id:
                            return str(spreadsheet_id)
                except (AttributeError, TypeError):
                    pass
    except Exception:
        pass
    
    # Streamlit secretsì—ì„œ ê°€ì ¸ì˜¤ê¸° (ì¶”ê°€ ì‹œí¬ë¦¿ ìœ„ì¹˜ í™•ì¸)
    try:
        if hasattr(st, "secrets"):
            # ì¶”ê°€ secrets ìœ„ì¹˜ í™•ì¸
            direct_id = st.secrets.get("oneon1_spreadsheet_id") or st.secrets.get("ONEOONE_SPREADSHEET_ID")
            if direct_id:
                return str(direct_id)
    except Exception:
        pass
    
    return ""

# ëª¨ë“ˆ ë¡œë“œ ì‹œì ì—ëŠ” Noneìœ¼ë¡œ ì´ˆê¸°í™”, ì‹¤ì œ ì‚¬ìš© ì‹œì ì— í•¨ìˆ˜ í˜¸ì¶œ
ONEOONE_SPREADSHEET_ID = None

def get_google_sheets_client():
    """Google Sheets í´ë¼ì´ì–¸íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # ë°©ë²• 0: Streamlit secretsì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ ì½ê¸° (ìµœìš°ì„ )
        try:
            google_sec = st.secrets.get("google") if hasattr(st, "secrets") else None
        except Exception:
            google_sec = None

        if google_sec:
            # 0-a) ì „ì²´ JSON ë¬¸ìì—´ ì €ì¥í•œ ê²½ìš°: google.credentials_json
            if "credentials_json" in google_sec and google_sec["credentials_json"]:
                raw = google_sec["credentials_json"]
                creds_info = json.loads(raw) if isinstance(raw, str) else dict(raw)
                creds = Credentials.from_service_account_info(creds_info, scopes=SCOPE)
                return gspread.authorize(creds)

            # 0-b) TOMLë¡œ í‚¤ë¥¼ ì¤‘ì²©(dict) ì €ì¥í•œ ê²½ìš°: google.service_account = { ... }
            if "service_account" in google_sec and google_sec["service_account"]:
                creds_info = dict(google_sec["service_account"])  # MappingProxyType ëŒ€ì‘
                creds = Credentials.from_service_account_info(creds_info, scopes=SCOPE)
                return gspread.authorize(creds)

        # ë°©ë²• 1: Streamlit secretsì—ì„œ ì§ì ‘ ì½ê¸° (ì¶”ê°€ ìœ„ì¹˜ í™•ì¸)
        try:
            if hasattr(st, "secrets"):
                direct_creds = st.secrets.get("GOOGLE_CREDENTIALS_JSON") or st.secrets.get("google_credentials_json")
                if direct_creds:
                    try:
                        creds_info = json.loads(direct_creds) if isinstance(direct_creds, str) else dict(direct_creds)
                        creds = Credentials.from_service_account_info(creds_info, scopes=SCOPE)
                        return gspread.authorize(creds)
                    except json.JSONDecodeError:
                        st.error("Streamlit secretsì˜ GOOGLE_CREDENTIALS_JSONì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                        return None
        except Exception:
            pass
        
        # ë°©ë²• 2: ì„œë¹„ìŠ¤ ê³„ì • JSON íŒŒì¼ ì½ê¸°
        service_account_file = "service_account.json"
        if os.path.exists(service_account_file):
            creds = Credentials.from_service_account_file(service_account_file, scopes=SCOPE)
            return gspread.authorize(creds)
        
        # ë°©ë²• 3: ì„¸ì…˜ ìƒíƒœì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ ì½ê¸°
        if 'google_credentials' in st.session_state and st.session_state.google_credentials:
            try:
                creds_info = json.loads(st.session_state.google_credentials)
                creds = Credentials.from_service_account_info(creds_info, scopes=SCOPE)
                return gspread.authorize(creds)
            except json.JSONDecodeError:
                st.error("ì €ì¥ëœ ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ê°€ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                return None
        
        # ì¸ì¦ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
        st.warning("Google Sheets ì—°ë™ì„ ìœ„í•´ ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return None
        
    except Exception as e:
        st.error(f"Google Sheets ì—°ë™ ì˜¤ë¥˜: {e}")
        return None

def get_oneon1_dataframe():
    """1on1 ì½”ì¹­ ë°ì´í„°ë¥¼ Google Sheetsì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        spreadsheet_id = get_oneon1_spreadsheet_id()
        if not spreadsheet_id:
            return None
        
        client = get_google_sheets_client()
        if not client:
            return None
        
        spreadsheet = client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet("Sheet1")
        records = worksheet.get_all_records()
        return pd.DataFrame(records)
    except Exception as e:
        st.error(f"1on1 ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def save_oneon1_record(data):
    """1on1 ì½”ì¹­ ê¸°ë¡ì„ Google Sheetsì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        spreadsheet_id = get_oneon1_spreadsheet_id()
        if not spreadsheet_id:
            st.error("1on1 ìŠ¤í”„ë ˆë“œì‹œíŠ¸ IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        client = get_google_sheets_client()
        if not client:
            return False
        
        spreadsheet = client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet("Sheet1")
        
        # ë°ì´í„°ë¥¼ í–‰ìœ¼ë¡œ ì¶”ê°€
        worksheet.append_row(data)
        return True
    except Exception as e:
        st.error(f"1on1 ê¸°ë¡ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def render_oneon1_form():
    """1on1 ì½”ì¹­ ê¸°ë¡ ì–‘ì‹ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.subheader("ğŸ“ 1on1 ì½”ì¹­ ê¸°ë¡ ì‘ì„±")
    
    with st.form("oneon1_form", clear_on_submit=False):
        # ì½”ì¹­ ë‚ ì§œ
        coaching_date = st.date_input(
            "ì½”ì¹­ ë‚ ì§œ",
            value=datetime.now().date(),
            help="1on1 ì½”ì¹­ì„ ì§„í–‰í•œ ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
        
        # ì°¸ì—¬ì ì •ë³´
        col1, col2 = st.columns(2)
        with col1:
            coach_name = st.text_input(
                "ì½”ì¹˜ ì´ë¦„",
                value=st.session_state.user_info.get('name', '') if st.session_state.get('user_info') else '',
                help="ì½”ì¹˜(ë¦¬ë”) ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"
            )
        with col2:
            coachee_name = st.text_input(
                "ì½”ì¹˜ì´ ì´ë¦„",
                placeholder="ì½”ì¹­ ë°›ëŠ” ì‚¬ëŒì˜ ì´ë¦„",
                help="ì½”ì¹˜ì´(êµ¬ì„±ì›) ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"
            )
        
        # ì½”ì¹­ ì£¼ì œ
        coaching_topic = st.text_input(
            "ì½”ì¹­ ì£¼ì œ",
            placeholder="ì˜ˆ: ì—…ë¬´ ì§„í–‰ ìƒí™©, ëª©í‘œ ë‹¬ì„±ë„, ì„±ì¥ í¬ì¸íŠ¸ ë“±",
            help="ì´ë²ˆ ì½”ì¹­ì—ì„œ ë‹¤ë£¬ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        # ì£¼ìš” ë‚´ìš©
        main_content = st.text_area(
            "ì£¼ìš” ë‚´ìš©",
            height=150,
            placeholder="ì½”ì¹­ì—ì„œ ë‹¤ë£¬ ì£¼ìš” ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”",
            help="ì½”ì¹­ ì¤‘ ë‚˜ëˆˆ ëŒ€í™”ì˜ í•µì‹¬ ë‚´ìš©ì„ ê¸°ë¡í•˜ì„¸ìš”"
        )
        
        # ì•¡ì…˜ ì•„ì´í…œ
        action_items = st.text_area(
            "ì•¡ì…˜ ì•„ì´í…œ",
            height=100,
            placeholder="ì˜ˆ: * ë‹¤ìŒì£¼ê¹Œì§€ ë¬¸ì„œ ì‘ì„± ì™„ë£Œ\n* ì›”ë§ê¹Œì§€ í”„ë¡œì íŠ¸ ê³„íš ìˆ˜ë¦½",
            help="ë‹¤ìŒ ì½”ì¹­ê¹Œì§€ í•´ì•¼ í•  ì¼ë“¤ì„ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        # ë‹¤ìŒ ë¯¸íŒ… ì¼ì •
        next_meeting = st.date_input(
            "ë‹¤ìŒ ë¯¸íŒ… ì¼ì •",
            value=None,
            help="ë‹¤ìŒ 1on1 ì½”ì¹­ ì˜ˆì •ì¼ì„ ì„ íƒí•˜ì„¸ìš” (ì„ íƒì‚¬í•­)"
        )
        
        # ì½”ì¹­ í‰ê°€
        st.markdown("### ì½”ì¹­ í‰ê°€")
        coaching_quality = st.slider(
            "ì½”ì¹­ ì§ˆ í‰ê°€",
            min_value=1,
            max_value=5,
            value=3,
            help="ì´ë²ˆ ì½”ì¹­ì˜ ì§ˆì„ 1-5ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”"
        )
        
        notes = st.text_area(
            "ê¸°íƒ€ ë©”ëª¨",
            height=100,
            placeholder="ì¶”ê°€ë¡œ ê¸°ë¡í•  ì‚¬í•­ì´ ìˆìœ¼ë©´ ì…ë ¥í•˜ì„¸ìš”",
            help="ê¸°íƒ€ ë©”ëª¨ ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­)"
        )
        
        # ì œì¶œ ë²„íŠ¼
        submitted = st.form_submit_button(
            "ğŸ“¤ ê¸°ë¡ ì €ì¥í•˜ê¸°",
            use_container_width=True,
            type="primary"
        )
        
        if submitted:
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            if not coach_name.strip():
                st.error("ì½”ì¹˜ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return False
            if not coachee_name.strip():
                st.error("ì½”ì¹˜ì´ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return False
            if not coaching_topic.strip():
                st.error("ì½”ì¹­ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return False
            
            # ë°ì´í„° ì¤€ë¹„
            now = datetime.now()
            timestamp = now.strftime("%Y. %m. %d %p %I:%M:%S").replace("AM", "ì˜¤ì „").replace("PM", "ì˜¤í›„")
            
            data = [
                timestamp,
                str(coaching_date),
                coach_name,
                coachee_name,
                coaching_topic,
                main_content,
                action_items,
                str(next_meeting) if next_meeting else "",
                coaching_quality,
                notes
            ]
            
            # ì €ì¥
            if save_oneon1_record(data):
                st.success("âœ… 1on1 ì½”ì¹­ ê¸°ë¡ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.error("âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            
            return True
    
    return False

def render_oneon1_history():
    """1on1 ì½”ì¹­ ê¸°ë¡ ë‚´ì—­ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.subheader("ğŸ“š 1on1 ì½”ì¹­ ê¸°ë¡ ë‚´ì—­")
    
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    df = get_oneon1_dataframe()
    
    if df is None or df.empty:
        st.info("ì•„ì§ ê¸°ë¡ëœ 1on1 ì½”ì¹­ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì‚¬ìš©ì í•„í„°ë§ (ë¡œê·¸ì¸ëœ ì‚¬ìš©ìë§Œ ìì‹ ì˜ ê¸°ë¡ ë³´ê¸°)
    user_name = None
    if st.session_state.get('logged_in') and st.session_state.get('user_info'):
        user_name = st.session_state.user_info.get('name', '')
    
    if user_name:
        # ì½”ì¹˜ ë˜ëŠ” ì½”ì¹˜ì´ë¡œ í•„í„°ë§
        if 'ì½”ì¹˜ ì´ë¦„' in df.columns and 'ì½”ì¹˜ì´ ì´ë¦„' in df.columns:
            filtered_df = df[
                (df['ì½”ì¹˜ ì´ë¦„'] == user_name) | 
                (df['ì½”ì¹˜ì´ ì´ë¦„'] == user_name)
            ]
        else:
            # ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ìœ¼ë¡œ ì‹œë„
            filtered_df = df
    else:
        filtered_df = df
    
    if filtered_df.empty:
        st.info(f"{user_name}ë‹˜ê³¼ ê´€ë ¨ëœ 1on1 ì½”ì¹­ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
    date_col = None
    for col in ['ì½”ì¹­ ë‚ ì§œ', 'ë‚ ì§œ', 'Date', 'date']:
        if col in filtered_df.columns:
            date_col = col
            break
    
    if date_col:
        try:
            filtered_df[date_col] = pd.to_datetime(filtered_df[date_col], errors='coerce')
            filtered_df = filtered_df.sort_values(by=date_col, ascending=False)
        except:
            pass
    
    # í•„í„°ë§ ì˜µì…˜
    col1, col2 = st.columns(2)
    with col1:
        search_keyword = st.text_input(
            "ğŸ” ê²€ìƒ‰",
            placeholder="ì£¼ì œ, ì°¸ì—¬ì ì´ë¦„ ë“±ìœ¼ë¡œ ê²€ìƒ‰",
            help="ì½”ì¹­ ì£¼ì œë‚˜ ì°¸ì—¬ì ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
    
    with col2:
        show_all = st.checkbox("ì „ì²´ ê¸°ë¡ ë³´ê¸°", value=False)
    
    # ê²€ìƒ‰ í•„í„° ì ìš©
    if search_keyword:
        keyword_lower = search_keyword.lower()
        mask = pd.Series([False] * len(filtered_df))
        for col in filtered_df.columns:
            mask = mask | filtered_df[col].astype(str).str.lower().str.contains(keyword_lower, na=False)
        filtered_df = filtered_df[mask]
    
    if not show_all and user_name:
        # ìì‹ ê³¼ ê´€ë ¨ëœ ê¸°ë¡ë§Œ ë³´ê¸° (ê¸°ë³¸ê°’)
        pass
    elif show_all:
        # ì „ì²´ ê¸°ë¡ ë³´ê¸°
        filtered_df = df
    
    # ê¸°ë¡ ì¹´ë“œë¡œ í‘œì‹œ
    st.markdown("---")
    for idx, row in filtered_df.iterrows():
        with st.expander(
            f"ğŸ“… {row.get('ì½”ì¹­ ë‚ ì§œ', row.get('ë‚ ì§œ', 'ë‚ ì§œ ë¯¸ì§€ì •'))} - {row.get('ì½”ì¹­ ì£¼ì œ', row.get('ì£¼ì œ', 'ì£¼ì œ ì—†ìŒ'))}",
            expanded=False
        ):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"**ì½”ì¹˜:** {row.get('ì½”ì¹˜ ì´ë¦„', 'N/A')}")
            with col2:
                st.markdown(f"**ì½”ì¹˜ì´:** {row.get('ì½”ì¹˜ì´ ì´ë¦„', 'N/A')}")
            
            st.markdown("---")
            
            if row.get('ì£¼ìš” ë‚´ìš©') or row.get('ë‚´ìš©'):
                st.markdown("### ì£¼ìš” ë‚´ìš©")
                st.write(row.get('ì£¼ìš” ë‚´ìš©', row.get('ë‚´ìš©', '')))
            
            if row.get('ì•¡ì…˜ ì•„ì´í…œ'):
                st.markdown("### ì•¡ì…˜ ì•„ì´í…œ")
                st.write(row.get('ì•¡ì…˜ ì•„ì´í…œ', ''))
            
            if row.get('ë‹¤ìŒ ë¯¸íŒ… ì¼ì •'):
                st.markdown(f"**ë‹¤ìŒ ë¯¸íŒ…:** {row.get('ë‹¤ìŒ ë¯¸íŒ… ì¼ì •', '')}")
            
            if row.get('ì½”ì¹­ ì§ˆ í‰ê°€'):
                st.markdown(f"**ì½”ì¹­ ì§ˆ í‰ê°€:** {'â­' * int(row.get('ì½”ì¹­ ì§ˆ í‰ê°€', 0))} ({row.get('ì½”ì¹­ ì§ˆ í‰ê°€', 0)}/5)")
            
            if row.get('ê¸°íƒ€ ë©”ëª¨'):
                st.markdown("### ê¸°íƒ€ ë©”ëª¨")
                st.write(row.get('ê¸°íƒ€ ë©”ëª¨', ''))

def format_cache_data_for_prompt(cache_data, data_type):
    """ìºì‹œ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    if not cache_data:
        return "ë°ì´í„° ì—†ìŒ"
    
    if isinstance(cache_data, list):
        if len(cache_data) == 0:
            return "ë°ì´í„° ì—†ìŒ"
        # ë¦¬ìŠ¤íŠ¸ì˜ ê° ë ˆì½”ë“œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        formatted = []
        for record in cache_data:
            if isinstance(record, dict):
                record_str = "\n".join([f"  - {k}: {v}" for k, v in record.items() if v and str(v).strip()])
                formatted.append(record_str)
        return "\n---\n".join(formatted)
    elif isinstance(cache_data, dict):
        return "\n".join([f"  - {k}: {v}" for k, v in cache_data.items() if v and str(v).strip()])
    else:
        return str(cache_data)

def create_word_document_from_feedback(feedback_text, title):
    """í”¼ë“œë°± í…ìŠ¤íŠ¸ë¥¼ Word ë¬¸ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    doc = Document()
    
    # í•œê¸€ í°íŠ¸ ì„¤ì • - ë¬¸ì„œì˜ ê¸°ë³¸ ìŠ¤íƒ€ì¼ì— í•œê¸€ í°íŠ¸ ì ìš©
    try:
        # Normal ìŠ¤íƒ€ì¼ ì„¤ì •
        normal_style = doc.styles['Normal']
        normal_font = normal_style.font
        normal_font.name = 'ë§‘ì€ ê³ ë”•'
        normal_font.size = Pt(11)
        normal_font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
        
        # Heading ìŠ¤íƒ€ì¼ë“¤ì—ë„ í•œê¸€ í°íŠ¸ ì„¤ì •
        for i in range(1, 10):
            try:
                heading_style = doc.styles[f'Heading {i}']
                heading_font = heading_style.font
                heading_font.name = 'ë§‘ì€ ê³ ë”•'
                heading_font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            except:
                pass
    except Exception as e:
        # í°íŠ¸ ì„¤ì • ì‹¤íŒ¨ ì‹œ ê³„ì† ì§„í–‰
        pass
    
    # ì œëª© ì¶”ê°€
    heading = doc.add_heading(title, 0)
    heading.alignment = 1  # ê°€ìš´ë° ì •ë ¬
    
    # ì œëª© í°íŠ¸ ì„¤ì •
    try:
        for run in heading.runs:
            run.font.name = 'ë§‘ì€ ê³ ë”•'
            run.font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            run.font.size = Pt(20)
            run.font.bold = True
    except:
        pass
    
    # ë‚ ì§œ ì¶”ê°€
    date_para = doc.add_paragraph(f"ìƒì„±ì¼: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}")
    date_para.alignment = 1  # ê°€ìš´ë° ì •ë ¬
    
    # ë‚ ì§œ í°íŠ¸ ì„¤ì •
    try:
        for run in date_para.runs:
            run.font.name = 'ë§‘ì€ ê³ ë”•'
            run.font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
    except:
        pass
    
    # ë¹ˆ ì¤„ ì¶”ê°€
    doc.add_paragraph()
    
    # í”¼ë“œë°± í…ìŠ¤íŠ¸ íŒŒì‹± ë° ì¶”ê°€
    lines = feedback_text.split('\n')
    current_para = None
    i = 0
    
    while i < len(lines):
        line = lines[i].strip()
        
        # ë¹ˆ ì¤„ ì²˜ë¦¬
        if not line:
            doc.add_paragraph()
            current_para = None
            i += 1
            continue
        
        # í‘œ ê°ì§€ (Markdown í‘œ í˜•ì‹: | ì»¬ëŸ¼1 | ì»¬ëŸ¼2 | ì»¬ëŸ¼3 |)
        if line.startswith('|') and line.endswith('|'):
            # í‘œ ì‹œì‘ ê°ì§€
            table_rows = []
            header_line = line
            separator_line = None
            
            # í—¤ë” ë‹¤ìŒ ì¤„ì´ êµ¬ë¶„ì„ ì¸ì§€ í™•ì¸
            if i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                if next_line.startswith('|') and ('---' in next_line or '===' in next_line or re.match(r'^\|\s*[-:=]+\s*\|', next_line)):
                    separator_line = next_line
                    i += 1  # êµ¬ë¶„ì„  ê±´ë„ˆë›°ê¸°
            
            # í—¤ë” í–‰ ì¶”ê°€
            header_cells = [cell.strip() for cell in header_line.split('|')[1:-1]]
            table_rows.append(header_cells)
            
            # ë°ì´í„° í–‰ ìˆ˜ì§‘
            i += 1
            while i < len(lines):
                current_line = lines[i].strip()
                if current_line.startswith('|') and current_line.endswith('|'):
                    cells = [cell.strip() for cell in current_line.split('|')[1:-1]]
                    if len(cells) == len(header_cells):  # ì»¬ëŸ¼ ìˆ˜ê°€ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ì—ë§Œ
                        table_rows.append(cells)
                        i += 1
                    else:
                        break
                else:
                    break
            
            # í‘œë¥¼ Word ë¬¸ì„œì— ì¶”ê°€
            if len(table_rows) > 0:
                try:
                    num_cols = len(table_rows[0])
                    num_rows = len(table_rows)
                    table = doc.add_table(rows=num_rows, cols=num_cols)
                    table.style = 'Light Grid Accent 1'  # í‘œ ìŠ¤íƒ€ì¼
                    
                    for row_idx, row_data in enumerate(table_rows):
                        for col_idx, cell_data in enumerate(row_data):
                            cell = table.rows[row_idx].cells[col_idx]
                            cell.text = cell_data
                            
                            # ì…€ í°íŠ¸ ì„¤ì •
                            for paragraph in cell.paragraphs:
                                for run in paragraph.runs:
                                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                                    run.font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                            
                            # í—¤ë” í–‰ì€ êµµê²Œ
                            if row_idx == 0:
                                for paragraph in cell.paragraphs:
                                    for run in paragraph.runs:
                                        run.font.bold = True
                except Exception as e:
                    # í‘œ ìƒì„± ì‹¤íŒ¨ ì‹œ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
                    for row_data in table_rows:
                        doc.add_paragraph(' | '.join(row_data))
                        try:
                            para = doc.paragraphs[-1]
                            for run in para.runs:
                                run.font.name = 'ë§‘ì€ ê³ ë”•'
                                run.font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                        except:
                            pass
            current_para = None
            i += 1
            continue
        
        # ì¼ë°˜ ì¤„ ì²˜ë¦¬
        # ì œëª© íŒ¨í„´ í™•ì¸ (###, ##, #, ë˜ëŠ” ìˆ«ì. íŒ¨í„´)
        if re.match(r'^#{1,3}\s+.+', line):
            # Markdown í—¤ë”©
            level = len(re.match(r'^(#{1,3})', line).group(1))
            text = re.sub(r'^#{1,3}\s+', '', line)
            heading_obj = None
            if level == 1:
                heading_obj = doc.add_heading(text, level=1)
            elif level == 2:
                heading_obj = doc.add_heading(text, level=2)
            else:
                heading_obj = doc.add_heading(text, level=3)
            # í—¤ë”©ì— í•œê¸€ í°íŠ¸ ì„¤ì •
            try:
                for run in heading_obj.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run.font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            except:
                pass
            current_para = None
            i += 1
        elif re.match(r'^\d+[\.\)]\s+.+', line):
            # ë²ˆí˜¸ ëª©ë¡
            para = doc.add_paragraph(line, style='List Number')
            # ë²ˆí˜¸ ëª©ë¡ì— í•œê¸€ í°íŠ¸ ì„¤ì •
            try:
                for run in para.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run.font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            except:
                pass
            current_para = None
            i += 1
        elif re.match(r'^[-*]\s+.+', line):
            # ë¶ˆë¦¿ ëª©ë¡
            text = re.sub(r'^[-*]\s+', '', line)
            para = doc.add_paragraph(text, style='List Bullet')
            # ë¶ˆë¦¿ ëª©ë¡ì— í•œê¸€ í°íŠ¸ ì„¤ì •
            try:
                for run in para.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run.font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            except:
                pass
            current_para = None
            i += 1
        elif re.match(r'^[â€¢Â·]\s+.+', line):
            # ë‹¤ë¥¸ ë¶ˆë¦¿ ë¬¸ì
            text = re.sub(r'^[â€¢Â·]\s+', '', line)
            para = doc.add_paragraph(text, style='List Bullet')
            # ë¶ˆë¦¿ ëª©ë¡ì— í•œê¸€ í°íŠ¸ ì„¤ì •
            try:
                for run in para.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run.font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            except:
                pass
            current_para = None
        else:
            # ì¼ë°˜ í…ìŠ¤íŠ¸
            if current_para is None:
                current_para = doc.add_paragraph(line)
                # ì¼ë°˜ í…ìŠ¤íŠ¸ì— í•œê¸€ í°íŠ¸ ì„¤ì •
                try:
                    for run in current_para.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run.font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                except:
                    pass
            else:
                run = current_para.add_run(f"\n{line}")
                # ì¶”ê°€ëœ runì— í•œê¸€ í°íŠ¸ ì„¤ì •
                try:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run.font._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                except:
                    pass
            i += 1
    
    # ë¬¸ì„œë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
    doc_io = BytesIO()
    doc.save(doc_io)
    doc_io.seek(0)
    return doc_io.getvalue()

def get_performance_coaching_feedback():
    """ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        if not GEMINI_API_KEY:
            return None, "Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        # ìºì‹œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        prefetch_cache = st.session_state.get('prefetch_cache') or {}
        if not isinstance(prefetch_cache, dict):
            prefetch_cache = {}
        
        archive_data = prefetch_cache.get('archive', [])
        mission_kpi_data = prefetch_cache.get('mission_kpi', [])
        ground_rule_data = prefetch_cache.get('ground_rule', [])
        
        # ë°ì´í„° í™•ì¸
        if not archive_data and not mission_kpi_data and not ground_rule_data:
            return None, "í”¼ë“œë°± ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”."
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—…ë¬´ ì„±ê³¼ ì°½ì¶œê³¼ ê´€ë ¨í•œ ìƒì„¸í•œ ì½”ì¹­ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**ì‚¬ìš©ìì˜ Snippet ì•„ì¹´ì´ë¸Œ:**
{format_cache_data_for_prompt(archive_data, 'archive')}

**ì¡°ì§ì˜ Mission & KPI:**
{format_cache_data_for_prompt(mission_kpi_data, 'mission_kpi')}

**Team Ground Rule:**
{format_cache_data_for_prompt(ground_rule_data, 'ground_rule')}

ìœ„ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•œ ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ì—…ë¬´ ì„±ê³¼ì˜ ê°•ì  ë¶„ì„
2. ì¡°ì§ ëª©í‘œì™€ì˜ ì—°ê³„ì„± í‰ê°€
3. ì„±ê³¼ ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì•¡ì…˜ ì•„ì´í…œ
4. íŒ€ ê·œì¹™ê³¼ì˜ ì¼ì¹˜ë„ ë° ê°œì„ ì 
5. í–¥í›„ ì„±ê³¼ ì°½ì¶œì„ ìœ„í•œ ì¡°ì–¸

í”¼ë“œë°±ì€ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        # Gemini API í˜¸ì¶œ
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ í™•ì¸
        model = None
        model_names_to_try = []
        last_error = None
        response = None
        
        # ë¨¼ì € ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        try:
            available_models = genai.list_models()
            # generateContentë¥¼ ì§€ì›í•˜ê³  Computer Useê°€ í•„ìš”ì—†ëŠ” ëª¨ë¸ ì°¾ê¸°
            for m in available_models:
                model_name = m.name
                # models/ ì ‘ë‘ì‚¬ ì œê±°
                if model_name.startswith('models/'):
                    model_name = model_name.replace('models/', '')
                
                # generateContentë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë¸ë§Œ
                if hasattr(m, 'supported_generation_methods') and 'generateContent' in m.supported_generation_methods:
                    # Computer Use ê´€ë ¨ ëª¨ë¸ ì œì™¸ (exp, 2.0-exp ë“±)
                    if 'exp' not in model_name.lower() and '2.0' not in model_name.lower():
                        if 'flash' in model_name.lower():
                            model_names_to_try.insert(0, model_name)  # flash ëª¨ë¸ ìš°ì„ 
                        elif 'pro' in model_name.lower():
                            model_names_to_try.append(model_name)
                        else:
                            model_names_to_try.append(model_name)
        except Exception as e:
            # ListModels ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª¨ë¸ ì‹œë„
            model_names_to_try = [
                'gemini-1.5-flash',
                'gemini-1.5-pro',
                'gemini-pro'
            ]
        
        # ë§Œì•½ ëª©ë¡ì´ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸ ì¶”ê°€
        if not model_names_to_try:
            model_names_to_try = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']
        
        # ëª¨ë¸ëª… ì‹œë„ (Computer Use ì˜¤ë¥˜ ê°ì§€ ë° ê±´ë„ˆë›°ê¸°)
        for model_name in model_names_to_try:
            try:
                model = genai.GenerativeModel(model_name)
                # Computer Use ì—†ì´ í…ìŠ¤íŠ¸ ìƒì„±ë§Œ ì‹œë„
                response = model.generate_content(
                    prompt,
                    generation_config={
                        "temperature": 0.7,
                        "top_p": 0.8,
                        "top_k": 40,
                    }
                )
                # ì„±ê³µì ìœ¼ë¡œ ì‘ë‹µì„ ë°›ì•˜ìœ¼ë©´ ì´ ëª¨ë¸ ì‚¬ìš©
                if response:
                    break
            except Exception as e:
                error_msg = str(e)
                last_error = error_msg
                # Computer Use ê´€ë ¨ ì˜¤ë¥˜ëŠ” ì´ ëª¨ë¸ì„ ê±´ë„ˆë›°ê¸°
                if 'Computer Use' in error_msg or 'computer-use' in error_msg.lower():
                    model = None
                    response = None
                    continue
                # 404 ì˜¤ë¥˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸ ì‹œë„
                if '404' in error_msg or 'not found' in error_msg.lower():
                    model = None
                    response = None
                    continue
                # ë‹¤ë¥¸ ì˜¤ë¥˜ë„ ì¼ë‹¨ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                model = None
                response = None
                continue
        
        if model is None or response is None:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì •ë³´ ì¶”ê°€
            available_info = ""
            try:
                available_models = genai.list_models()
                available_names = [m.name for m in available_models if hasattr(m, 'supported_generation_methods') and 'generateContent' in m.supported_generation_methods]
                if available_names:
                    available_info = f" ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {available_names[:5]}"
            except:
                pass
            raise Exception(f"ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error}. ì‹œë„í•œ ëª¨ë¸: {model_names_to_try}.{available_info} API í‚¤ì™€ ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if hasattr(response, 'text'):
            feedback_text = response.text
        elif hasattr(response, 'candidates') and len(response.candidates) > 0:
            if hasattr(response.candidates[0], 'content'):
                if hasattr(response.candidates[0].content, 'parts'):
                    feedback_text = response.candidates[0].content.parts[0].text
                else:
                    feedback_text = str(response.candidates[0].content)
            else:
                feedback_text = str(response.candidates[0])
        else:
            feedback_text = str(response)
        
        return feedback_text, None
        
    except Exception as e:
        return None, f"í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def get_growth_coaching_feedback():
    """ì„±ì¥ ì½”ì¹­ í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        if not GEMINI_API_KEY:
            return None, "Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        # ìºì‹œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        prefetch_cache = st.session_state.get('prefetch_cache', {})
        
        archive_data = prefetch_cache.get('archive', [])
        cdp_data = prefetch_cache.get('cdp', [])
        idp_data = prefetch_cache.get('idp', [])
        mission_kpi_data = prefetch_cache.get('mission_kpi', [])
        ground_rule_data = prefetch_cache.get('ground_rule', [])
        
        # ë°ì´í„° í™•ì¸
        if not archive_data and not cdp_data and not idp_data and not mission_kpi_data and not ground_rule_data:
            return None, "í”¼ë“œë°± ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”."
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„±ì¥ê³¼ ê´€ë ¨í•œ ìƒì„¸í•œ ì½”ì¹­ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**ì‚¬ìš©ìì˜ Snippet ì•„ì¹´ì´ë¸Œ:**
{format_cache_data_for_prompt(archive_data, 'archive')}

**ê²½ë ¥ ê°œë°œ ê³„íš (CDP):**
{format_cache_data_for_prompt(cdp_data, 'cdp')}

**ê°œì¸ ê°œë°œ ê³„íš (IDP):**
{format_cache_data_for_prompt(idp_data, 'idp')}

**ì¡°ì§ì˜ Mission & KPI:**
{format_cache_data_for_prompt(mission_kpi_data, 'mission_kpi')}

**Team Ground Rule:**
{format_cache_data_for_prompt(ground_rule_data, 'ground_rule')}

ìœ„ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•œ ì„±ì¥ ì½”ì¹­ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ì„±ì¥ ìƒíƒœì™€ ì—­ëŸ‰ ë¶„ì„
2. ê°œì¸ ê°œë°œ ê³„íš(IDP) ë° ê²½ë ¥ ê°œë°œ ê³„íš(CDP) ë‹¬ì„±ë„ í‰ê°€
3. ì¡°ì§ ëª©í‘œì™€ì˜ ì •ë ¬ë„ ë° ì„±ì¥ ë°©í–¥ì„± ì œì‹œ
4. ì„±ì¥ì„ ìœ„í•œ êµ¬ì²´ì ì¸ í•™ìŠµ ë° ê°œë°œ ì•¡ì…˜ ì•„ì´í…œ
5. ë‹¤ìŒ ë‹¨ê³„ ì„±ì¥ì„ ìœ„í•œ ì¡°ì–¸ ë° ë¡œë“œë§µ

í”¼ë“œë°±ì€ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        # Gemini API í˜¸ì¶œ
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ í™•ì¸
        model = None
        model_names_to_try = []
        last_error = None
        response = None
        
        # ë¨¼ì € ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        try:
            available_models = genai.list_models()
            # generateContentë¥¼ ì§€ì›í•˜ê³  Computer Useê°€ í•„ìš”ì—†ëŠ” ëª¨ë¸ ì°¾ê¸°
            for m in available_models:
                model_name = m.name
                # models/ ì ‘ë‘ì‚¬ ì œê±°
                if model_name.startswith('models/'):
                    model_name = model_name.replace('models/', '')
                
                # generateContentë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë¸ë§Œ
                if hasattr(m, 'supported_generation_methods') and 'generateContent' in m.supported_generation_methods:
                    # Computer Use ê´€ë ¨ ëª¨ë¸ ì œì™¸ (exp, 2.0-exp ë“±)
                    if 'exp' not in model_name.lower() and '2.0' not in model_name.lower():
                        if 'flash' in model_name.lower():
                            model_names_to_try.insert(0, model_name)  # flash ëª¨ë¸ ìš°ì„ 
                        elif 'pro' in model_name.lower():
                            model_names_to_try.append(model_name)
                        else:
                            model_names_to_try.append(model_name)
        except Exception as e:
            # ListModels ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª¨ë¸ ì‹œë„
            model_names_to_try = [
                'gemini-1.5-flash',
                'gemini-1.5-pro',
                'gemini-pro'
            ]
        
        # ë§Œì•½ ëª©ë¡ì´ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸ ì¶”ê°€
        if not model_names_to_try:
            model_names_to_try = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']
        
        # ëª¨ë¸ëª… ì‹œë„ (Computer Use ì˜¤ë¥˜ ê°ì§€ ë° ê±´ë„ˆë›°ê¸°)
        for model_name in model_names_to_try:
            try:
                model = genai.GenerativeModel(model_name)
                # Computer Use ì—†ì´ í…ìŠ¤íŠ¸ ìƒì„±ë§Œ ì‹œë„
                response = model.generate_content(
                    prompt,
                    generation_config={
                        "temperature": 0.7,
                        "top_p": 0.8,
                        "top_k": 40,
                    }
                )
                # ì„±ê³µì ìœ¼ë¡œ ì‘ë‹µì„ ë°›ì•˜ìœ¼ë©´ ì´ ëª¨ë¸ ì‚¬ìš©
                if response:
                    break
            except Exception as e:
                error_msg = str(e)
                last_error = error_msg
                # Computer Use ê´€ë ¨ ì˜¤ë¥˜ëŠ” ì´ ëª¨ë¸ì„ ê±´ë„ˆë›°ê¸°
                if 'Computer Use' in error_msg or 'computer-use' in error_msg.lower():
                    model = None
                    response = None
                    continue
                # 404 ì˜¤ë¥˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸ ì‹œë„
                if '404' in error_msg or 'not found' in error_msg.lower():
                    model = None
                    response = None
                    continue
                # ë‹¤ë¥¸ ì˜¤ë¥˜ë„ ì¼ë‹¨ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                model = None
                response = None
                continue
        
        if model is None or response is None:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì •ë³´ ì¶”ê°€
            available_info = ""
            try:
                available_models = genai.list_models()
                available_names = [m.name for m in available_models if hasattr(m, 'supported_generation_methods') and 'generateContent' in m.supported_generation_methods]
                if available_names:
                    available_info = f" ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {available_names[:5]}"
            except:
                pass
            raise Exception(f"ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error}. ì‹œë„í•œ ëª¨ë¸: {model_names_to_try}.{available_info} API í‚¤ì™€ ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if hasattr(response, 'text'):
            feedback_text = response.text
        elif hasattr(response, 'candidates') and len(response.candidates) > 0:
            if hasattr(response.candidates[0], 'content'):
                if hasattr(response.candidates[0].content, 'parts'):
                    feedback_text = response.candidates[0].content.parts[0].text
                else:
                    feedback_text = str(response.candidates[0].content)
            else:
                feedback_text = str(response.candidates[0])
        else:
            feedback_text = str(response)
        
        return feedback_text, None
        
    except Exception as e:
        return None, f"í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def render_performance_feedback():
    """ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°±ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.subheader("ğŸ“Š ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°±")
    st.markdown("ì‚¬ìš©ìì˜ ì—…ë¬´ ì„±ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì½”ì¹­ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.")
    
    # ë°ì´í„° ìƒíƒœ í‘œì‹œ
    prefetch_cache = st.session_state.get('prefetch_cache') or {}
    if not isinstance(prefetch_cache, dict):
        prefetch_cache = {}
    archive_data = prefetch_cache.get('archive', [])
    mission_kpi_data = prefetch_cache.get('mission_kpi', [])
    ground_rule_data = prefetch_cache.get('ground_rule', [])
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Snippet ì•„ì¹´ì´ë¸Œ", f"{len(archive_data)}ê°œ" if archive_data else "ì—†ìŒ")
    with col2:
        st.metric("Mission & KPI", f"{len(mission_kpi_data)}ê°œ" if mission_kpi_data else "ì—†ìŒ")
    with col3:
        st.metric("Team Ground Rule", f"{len(ground_rule_data)}ê°œ" if ground_rule_data else "ì—†ìŒ")
    
    if not GEMINI_API_KEY:
        st.warning("âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    if st.button("ğŸ” ì„±ê³¼ í”¼ë“œë°± ìƒì„±í•˜ê¸°", use_container_width=True, type="primary"):
        with st.spinner("AIê°€ í”¼ë“œë°±ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
            feedback, error = get_performance_coaching_feedback()
            
            if error:
                st.error(error)
            elif feedback:
                st.success("âœ… ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°±ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.markdown("---")
                st.markdown("### ğŸ“‹ ì½”ì¹­ í”¼ë“œë°±")
                st.markdown(feedback)
                
                # í”¼ë“œë°± ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (Word íŒŒì¼)
                word_bytes = create_word_document_from_feedback(feedback, "ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°±")
                st.download_button(
                    label="ğŸ“¥ í”¼ë“œë°± ë‹¤ìš´ë¡œë“œ (Word)",
                    data=word_bytes,
                    file_name=f"ì„±ê³¼_ì½”ì¹­_í”¼ë“œë°±_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
            else:
                st.warning("í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def render_performance_feedback_auto():
    """ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°±ì„ ìë™ìœ¼ë¡œ ìƒì„±í•˜ê³  í‘œì‹œí•©ë‹ˆë‹¤."""
    with st.expander("ğŸ“Š ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°±", expanded=True):
        st.markdown("ì‚¬ìš©ìì˜ ì—…ë¬´ ì„±ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì½”ì¹­ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.")
        
        feedback_placeholder = st.empty()
        with feedback_placeholder:
            with st.spinner("ğŸ¤– ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°± ìƒì„± ì¤‘..."):
                feedback, error = get_performance_coaching_feedback()
        
        feedback_placeholder.empty()
        
        if error:
            st.error(f"âŒ {error}")
        elif feedback:
            st.markdown("### ğŸ“‹ ì½”ì¹­ í”¼ë“œë°±")
            st.markdown(feedback)
            
            # í”¼ë“œë°± ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (Word íŒŒì¼)
            word_bytes = create_word_document_from_feedback(feedback, "ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°±")
            st.download_button(
                label="ğŸ“¥ í”¼ë“œë°± ë‹¤ìš´ë¡œë“œ (Word)",
                data=word_bytes,
                file_name=f"ì„±ê³¼_ì½”ì¹­_í”¼ë“œë°±_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        else:
            st.warning("í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def render_growth_feedback():
    """ì„±ì¥ ì½”ì¹­ í”¼ë“œë°±ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.subheader("ğŸŒ± ì„±ì¥ ì½”ì¹­ í”¼ë“œë°±")
    st.markdown("ì‚¬ìš©ìì˜ ì„±ì¥ ìƒí™©ì„ ë¶„ì„í•˜ì—¬ ì½”ì¹­ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.")
    
    # ë°ì´í„° ìƒíƒœ í‘œì‹œ
    prefetch_cache = st.session_state.get('prefetch_cache') or {}
    if not isinstance(prefetch_cache, dict):
        prefetch_cache = {}
    archive_data = prefetch_cache.get('archive', [])
    cdp_data = prefetch_cache.get('cdp', [])
    idp_data = prefetch_cache.get('idp', [])
    mission_kpi_data = prefetch_cache.get('mission_kpi', [])
    ground_rule_data = prefetch_cache.get('ground_rule', [])
    
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        st.metric("Snippet", f"{len(archive_data)}ê°œ" if archive_data else "ì—†ìŒ")
    with col2:
        st.metric("CDP", f"{len(cdp_data)}ê°œ" if cdp_data else "ì—†ìŒ")
    with col3:
        st.metric("IDP", f"{len(idp_data)}ê°œ" if idp_data else "ì—†ìŒ")
    with col4:
        st.metric("Mission & KPI", f"{len(mission_kpi_data)}ê°œ" if mission_kpi_data else "ì—†ìŒ")
    with col5:
        st.metric("Ground Rule", f"{len(ground_rule_data)}ê°œ" if ground_rule_data else "ì—†ìŒ")
    
    if not GEMINI_API_KEY:
        st.warning("âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    if st.button("ğŸ” ì„±ì¥ í”¼ë“œë°± ìƒì„±í•˜ê¸°", use_container_width=True, type="primary"):
        with st.spinner("AIê°€ í”¼ë“œë°±ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
            feedback, error = get_growth_coaching_feedback()
            
            if error:
                st.error(error)
            elif feedback:
                st.success("âœ… ì„±ì¥ ì½”ì¹­ í”¼ë“œë°±ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.markdown("---")
                st.markdown("### ğŸ“‹ ì½”ì¹­ í”¼ë“œë°±")
                st.markdown(feedback)
                
                # í”¼ë“œë°± ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (Word íŒŒì¼)
                word_bytes = create_word_document_from_feedback(feedback, "ì„±ì¥ ì½”ì¹­ í”¼ë“œë°±")
                st.download_button(
                    label="ğŸ“¥ í”¼ë“œë°± ë‹¤ìš´ë¡œë“œ (Word)",
                    data=word_bytes,
                    file_name=f"ì„±ì¥_ì½”ì¹­_í”¼ë“œë°±_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
            else:
                st.warning("í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def render_growth_feedback_auto():
    """ì„±ì¥ ì½”ì¹­ í”¼ë“œë°±ì„ ìë™ìœ¼ë¡œ ìƒì„±í•˜ê³  í‘œì‹œí•©ë‹ˆë‹¤."""
    with st.expander("ğŸŒ± ì„±ì¥ ì½”ì¹­ í”¼ë“œë°±", expanded=True):
        st.markdown("ì‚¬ìš©ìì˜ ì„±ì¥ ìƒí™©ì„ ë¶„ì„í•˜ì—¬ ì½”ì¹­ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.")
        
        feedback_placeholder = st.empty()
        with feedback_placeholder:
            with st.spinner("ğŸ¤– ì„±ì¥ ì½”ì¹­ í”¼ë“œë°± ìƒì„± ì¤‘..."):
                feedback, error = get_growth_coaching_feedback()
        
        feedback_placeholder.empty()
        
        if error:
            st.error(f"âŒ {error}")
        elif feedback:
            st.markdown("### ğŸ“‹ ì½”ì¹­ í”¼ë“œë°±")
            st.markdown(feedback)
            
            # í”¼ë“œë°± ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (Word íŒŒì¼)
            word_bytes = create_word_document_from_feedback(feedback, "ì„±ì¥ ì½”ì¹­ í”¼ë“œë°±")
            st.download_button(
                label="ğŸ“¥ í”¼ë“œë°± ë‹¤ìš´ë¡œë“œ (Word)",
                data=word_bytes,
                file_name=f"ì„±ì¥_ì½”ì¹­_í”¼ë“œë°±_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        else:
            st.warning("í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def ensure_cache_data():
    """í•„ìš”í•œ ìºì‹œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ë¡œë“œí•©ë‹ˆë‹¤."""
    # prefetch_cache ì´ˆê¸°í™”
    if 'prefetch_cache' not in st.session_state:
        st.session_state.prefetch_cache = {}
    
    prefetch_cache = st.session_state.prefetch_cache
    if not isinstance(prefetch_cache, dict):
        prefetch_cache = {}
        st.session_state.prefetch_cache = prefetch_cache
    
    user_info = st.session_state.get('user_info')
    if not user_info:
        return False
    
    user_name = user_info.get('name')
    if not user_name:
        return False
    
    missing_data = []
    need_load = False
    
    # ìºì‹œ í™•ì¸
    if not prefetch_cache.get('archive'):
        missing_data.append('Snippet ì•„ì¹´ì´ë¸Œ')
        need_load = True
    if not prefetch_cache.get('cdp'):
        missing_data.append('CDP')
        need_load = True
    if not prefetch_cache.get('idp'):
        missing_data.append('IDP')
        need_load = True
    if not prefetch_cache.get('mission_kpi'):
        missing_data.append('Mission & KPI')
        need_load = True
    if not prefetch_cache.get('ground_rule'):
        missing_data.append('Team Ground Rule')
        need_load = True
    
    if not need_load:
        return True
    
    # ë°ì´í„° ë¡œë”©
    status_text = st.empty()
    progress_bar = st.progress(0)
    
    # 1. Snippet ì•„ì¹´ì´ë¸Œ ë¡œë”©
    if not prefetch_cache.get('archive'):
        status_text.info("ğŸ“š Snippet ì•„ì¹´ì´ë¸Œ ë°ì´í„° ë¡œë”© ì¤‘...")
        progress_bar.progress(10)
        try:
            import sys
            import Archive
            
            # main.py ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
            main_module = None
            get_client = None
            spreadsheet_id = None
            
            # ë°©ë²• 1: sys.modulesì—ì„œ ì°¾ê¸°
            main_module = sys.modules.get('main')
            
            # ë°©ë²• 2: ì§ì ‘ import ì‹œë„
            if not main_module:
                try:
                    import main as main_mod
                    main_module = main_mod
                except Exception:
                    pass
            
            # ë°©ë²• 3: importlibë¡œ ë¡œë“œ ì‹œë„
            if not main_module:
                try:
                    import importlib
                    main_module = importlib.import_module('main')
                except Exception:
                    pass
            
            # main.pyì˜ í•¨ìˆ˜ë“¤ì„ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ë¡œë“œ
            main_get_client = None
            main_spreadsheet_id = None
            
            if main_module:
                main_get_client = getattr(main_module, 'get_google_sheets_client', None)
                main_spreadsheet_id = getattr(main_module, 'SPREADSHEET_ID', None)
            
            # ë°ì´í„° ë¡œë“œ ì‹œë„
            archive_df = None
            
            # ë””ë²„ê¹… ì •ë³´ ìˆ˜ì§‘
            debug_info = []
            debug_info.append(f"ì‚¬ìš©ì ì´ë¦„: {user_name}")
            debug_info.append(f"Google Sheets ì—°ê²°: {st.session_state.get('google_sheets_connected', False)}")
            debug_info.append(f"main_module ì°¾ê¸°: {main_module is not None}")
            debug_info.append(f"main.pyì—ì„œ get_client ì°¾ê¸°: {main_get_client is not None}")
            debug_info.append(f"main.pyì—ì„œ SPREADSHEET_ID ì°¾ê¸°: {main_spreadsheet_id}")
            
            # ìµœì¢… ê°’ ê²°ì • (ìš°ì„ ìˆœìœ„: main.py > 1on1.py > í•˜ë“œì½”ë”©)
            if main_get_client:
                get_client = main_get_client
                debug_info.append("âœ… main.pyì˜ get_google_sheets_client ì‚¬ìš©")
            else:
                get_client = get_google_sheets_client
                debug_info.append("âœ… 1on1.pyì˜ get_google_sheets_client ì‚¬ìš©")
            
            if main_spreadsheet_id:
                spreadsheet_id = main_spreadsheet_id
                debug_info.append(f"âœ… main.pyì˜ SPREADSHEET_ID ì‚¬ìš©: {spreadsheet_id}")
            else:
                spreadsheet_id = "1THmwStR6p0_SUyLEV6-edT0kigANvTCPOkAzN7NaEQE"
                debug_info.append(f"âœ… í•˜ë“œì½”ë”©ëœ spreadsheet_id ì‚¬ìš©: {spreadsheet_id}")
            
            debug_info.append(f"ìµœì¢… get_client: {get_client is not None} (íƒ€ì…: {type(get_client).__name__})")
            debug_info.append(f"ìµœì¢… spreadsheet_id: {spreadsheet_id}")
            
            # 1ìˆœìœ„: Google Sheetsì—ì„œ ë¡œë“œ
            if get_client and spreadsheet_id:
                # google_sheets_connected ìƒíƒœì™€ ë¬´ê´€í•˜ê²Œ ì‹œë„ (ì—°ê²° ìƒíƒœê°€ ì˜ëª» í‘œì‹œë  ìˆ˜ ìˆìŒ)
                try:
                    debug_info.append(f"Google Sheetsì—ì„œ ë¡œë“œ ì‹œë„ ì¤‘... (spreadsheet_id: {spreadsheet_id})")
                    # get_clientê°€ í•¨ìˆ˜ì¸ì§€ í™•ì¸
                    if callable(get_client):
                        debug_info.append("get_clientëŠ” í˜¸ì¶œ ê°€ëŠ¥í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤")
                        archive_df = Archive.get_snippets_from_google_sheets(get_client, spreadsheet_id)
                    else:
                        debug_info.append(f"get_clientê°€ í•¨ìˆ˜ê°€ ì•„ë‹™ë‹ˆë‹¤: {type(get_client)}")
                        # ì§ì ‘ ì‹œë„
                        client = None
                        if main_module and hasattr(main_module, 'get_google_sheets_client'):
                            client = main_module.get_google_sheets_client()
                            if client:
                                spreadsheet = client.open_by_key(spreadsheet_id)
                                worksheet = spreadsheet.worksheet("Sheet1")
                                records = worksheet.get_all_records()
                                archive_df = pd.DataFrame(records)
                            else:
                                archive_df = None
                        else:
                            archive_df = None
                    
                    if archive_df is not None and not archive_df.empty:
                        debug_info.append(f"Google Sheets ë¡œë“œ ì„±ê³µ: {len(archive_df)}ê°œ í–‰, {len(archive_df.columns)}ê°œ ì»¬ëŸ¼")
                    else:
                        debug_info.append("Google Sheets ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ None")
                except Exception as gs_error:
                    import traceback
                    error_trace = traceback.format_exc()
                    debug_info.append(f"Google Sheets ë¡œë”© ì‹¤íŒ¨: {str(gs_error)}")
                    debug_info.append(f"ìƒì„¸ ì˜¤ë¥˜: {error_trace[:500]}")  # ì²˜ìŒ 500ìë§Œ
                    archive_df = None
            else:
                debug_info.append(f"ì¡°ê±´ ë¶ˆë§Œì¡± - get_client: {get_client is not None}, spreadsheet_id: {spreadsheet_id}")
                if not get_client:
                    debug_info.append("get_client í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                if not spreadsheet_id:
                    debug_info.append("spreadsheet_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # 2ìˆœìœ„: ë¡œì»¬ CSVì—ì„œ ë¡œë“œ
            if archive_df is None or (hasattr(archive_df, 'empty') and archive_df.empty):
                try:
                    debug_info.append("ë¡œì»¬ CSVì—ì„œ ë¡œë“œ ì‹œë„ ì¤‘...")
                    archive_df = Archive.get_snippets_from_local_csv()
                    if archive_df is not None and not archive_df.empty:
                        debug_info.append(f"ë¡œì»¬ CSV ë¡œë“œ ì„±ê³µ: {len(archive_df)}ê°œ í–‰")
                    else:
                        debug_info.append("ë¡œì»¬ CSV ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ íŒŒì¼ ì—†ìŒ")
                except Exception as csv_error:
                    debug_info.append(f"ë¡œì»¬ CSV ë¡œë”© ì‹¤íŒ¨: {str(csv_error)}")
                    archive_df = None
            
            # ë°ì´í„° ì²˜ë¦¬
            if archive_df is not None and not archive_df.empty:
                debug_info.append(f"ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼: {list(archive_df.columns)}")
                
                # ì»¬ëŸ¼ëª… í™•ì¸ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ, ê³µë°± ì œê±°)
                name_column = None
                for col in archive_df.columns:
                    col_clean = str(col).strip().lower()
                    if 'ì´ë¦„' in str(col) or 'name' in col_clean:
                        name_column = col
                        debug_info.append(f"ì´ë¦„ ì»¬ëŸ¼ ì°¾ìŒ: {col}")
                        break
                
                if name_column:
                    # ì‚¬ìš©ì ì´ë¦„ìœ¼ë¡œ í•„í„°ë§
                    user_archive = archive_df[archive_df[name_column] == user_name]
                    debug_info.append(f"ì‚¬ìš©ì '{user_name}' ë§¤ì¹­ ê²°ê³¼: {len(user_archive)}ê°œ í–‰")
                    
                    # ì •í™•íˆ ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
                    if user_archive.empty:
                        # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ê³µë°± ì œê±°)
                        user_name_clean = str(user_name).strip()
                        for idx, row in archive_df.iterrows():
                            row_name = str(row[name_column]).strip() if pd.notna(row[name_column]) else ""
                            if user_name_clean == row_name:
                                user_archive = archive_df[archive_df.index == idx]
                                debug_info.append(f"ë¶€ë¶„ ë§¤ì¹­ ì„±ê³µ: ì¸ë±ìŠ¤ {idx}")
                                break
                    
                    prefetch_cache['archive'] = user_archive.to_dict('records') if not user_archive.empty else []
                else:
                    debug_info.append("ì´ë¦„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - ì „ì²´ ë°ì´í„° ì‚¬ìš©")
                    # ì´ë¦„ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì „ì²´ ë°ì´í„° ì‚¬ìš©
                    prefetch_cache['archive'] = archive_df.to_dict('records')
            else:
                debug_info.append("ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆê±°ë‚˜ None")
                prefetch_cache['archive'] = []
           
            
            # ë¡œë”© ì‹¤íŒ¨ ì‹œ ê²½ê³  í‘œì‹œ
            if not prefetch_cache.get('archive'):
                if debug_info:
                    # ë§ˆì§€ë§‰ ëª‡ ê°œ ë””ë²„ê·¸ ë©”ì‹œì§€ë§Œ í‘œì‹œ
                    recent_errors = [d for d in debug_info if any(keyword in d for keyword in ['ì‹¤íŒ¨', 'ì—†ìŒ', 'ë¹„ì–´', 'None', 'ë¶ˆë§Œì¡±', 'ì°¾ì„ ìˆ˜ ì—†'])]
                    if recent_errors:
                        error_msg = " | ".join(recent_errors[-3:])
                        st.error(f"âŒ Snippet ì•„ì¹´ì´ë¸Œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n**ì˜¤ë¥˜ ì •ë³´:**\n{error_msg}\n\n**í•´ê²° ë°©ë²•:**\n- ìœ„ì˜ 'ğŸ” Snippet ì•„ì¹´ì´ë¸Œ ë¡œë”© ìƒì„¸ ì •ë³´'ë¥¼ í¼ì³ì„œ ìì„¸í•œ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n- Google Sheets ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.\n- ì‚¬ìš©ì ì´ë¦„ì´ ë°ì´í„°ì˜ 'ì´ë¦„' ì»¬ëŸ¼ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
                
        except Exception as e:
            # ì—ëŸ¬ ìƒì„¸ ì •ë³´ë¥¼ ë¡œê·¸ë¡œ ë‚¨ê¸°ê¸°
            import traceback
            error_detail = traceback.format_exc()
            st.warning(f"âš ï¸ Snippet ì•„ì¹´ì´ë¸Œ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ë””ë²„ê·¸ ì •ë³´ëŠ” ê°œë°œ í™˜ê²½ì—ì„œë§Œ í‘œì‹œ
            if st.session_state.get('debug_mode', False):
                st.text(f"ìƒì„¸ ì˜¤ë¥˜:\n{error_detail}")
            prefetch_cache['archive'] = []
    
    # 2. CDP ë¡œë”©
    if not prefetch_cache.get('cdp'):
        status_text.info("ğŸ“Š CDP ë°ì´í„° ë¡œë”© ì¤‘...")
        progress_bar.progress(30)
        try:
            import cdp
            cdp_df = cdp._fetch_cdp_dataframe()
            if cdp_df is not None and not cdp_df.empty:
                normalized = {c.strip(): c for c in cdp_df.columns}
                name_col = normalized.get("ì´ë¦„") or normalized.get("name") or list(cdp_df.columns)[0]
                user_cdp = cdp_df[cdp_df[name_col] == user_name]
                prefetch_cache['cdp'] = user_cdp.to_dict('records') if not user_cdp.empty else []
            else:
                prefetch_cache['cdp'] = []
        except Exception:
            prefetch_cache['cdp'] = []
    
    # 3. IDP ë¡œë”©
    if not prefetch_cache.get('idp'):
        status_text.info("ğŸ¯ IDP ë°ì´í„° ë¡œë”© ì¤‘...")
        progress_bar.progress(50)
        try:
            import idp_usage
            idp_df = idp_usage.fetch_idp_dataframe()
            if idp_df is not None and not idp_df.empty:
                if 'ì´ë¦„' in idp_df.columns:
                    user_idp = idp_df[idp_df['ì´ë¦„'] == user_name]
                    prefetch_cache['idp'] = user_idp.to_dict('records') if not user_idp.empty else []
                else:
                    prefetch_cache['idp'] = idp_df.to_dict('records')
            else:
                prefetch_cache['idp'] = []
        except Exception:
            prefetch_cache['idp'] = []
    
    # 4. Mission & KPI ë¡œë”©
    if not prefetch_cache.get('mission_kpi'):
        status_text.info("ğŸ¯ Mission & KPI ë°ì´í„° ë¡œë”© ì¤‘...")
        progress_bar.progress(70)
        try:
            import organization
            mission_kpi_df = organization.get_sheet_data(organization.MISSION_KPI_SHEET_ID)
            if mission_kpi_df is not None and not mission_kpi_df.empty:
                prefetch_cache['mission_kpi'] = mission_kpi_df.to_dict('records')
            else:
                prefetch_cache['mission_kpi'] = []
        except Exception:
            prefetch_cache['mission_kpi'] = []
    
    # 5. Team Ground Rule ë¡œë”©
    if not prefetch_cache.get('ground_rule'):
        status_text.info("ğŸ“‹ Team Ground Rule ë°ì´í„° ë¡œë”© ì¤‘...")
        progress_bar.progress(90)
        try:
            import organization
            ground_rule_df = organization.get_sheet_data(organization.GROUND_RULE_SHEET_ID)
            if ground_rule_df is not None and not ground_rule_df.empty:
                prefetch_cache['ground_rule'] = ground_rule_df.to_dict('records')
            else:
                prefetch_cache['ground_rule'] = []
        except Exception:
            prefetch_cache['ground_rule'] = []
    
    # ìºì‹œ ì €ì¥
    st.session_state.prefetch_cache = prefetch_cache
    
    status_text.empty()
    progress_bar.empty()
    
    return True

def render_oneon1_embedded():
    """1on1 ì½”ì¹­ í˜ì´ì§€ë¥¼ ì„ë² ë“œ ëª¨ë“œë¡œ ë Œë”ë§í•©ë‹ˆë‹¤ (main.pyì—ì„œ ì‚¬ìš©)."""
    st.title("ğŸ‘¥ 1on1 ì½”ì¹­")
    st.markdown("AI ê¸°ë°˜ ì½”ì¹­ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.")
    st.markdown("---")
    
    # ìºì‹œ ë°ì´í„° í™•ì¸ ë° ë¡œë”©
    status_container = st.container()
    with status_container:
        status_placeholder = st.empty()
        progress_placeholder = st.empty()
        
        status_placeholder.info("ğŸ“Š ë°ì´í„° í™•ì¸ ì¤‘...")
        progress_placeholder.progress(0)
        
        # ë°ì´í„° ë¡œë”©
        status_placeholder.info("ğŸ“¥ ë°ì´í„° ë¡œë”© ì¤‘...")
        progress_placeholder.progress(0.2)
        
        ensure_cache_data()
        
        # ë°ì´í„° ë¶„ì„ ì¤‘
        status_placeholder.info("ğŸ” ë°ì´í„° ë¶„ì„ ì¤‘...")
        progress_placeholder.progress(0.5)
        
        # ìºì‹œ ìƒíƒœ í™•ì¸
        prefetch_cache = st.session_state.get('prefetch_cache') or {}
        if not isinstance(prefetch_cache, dict):
            prefetch_cache = {}
        
        archive_count = len(prefetch_cache.get('archive', []))
        cdp_count = len(prefetch_cache.get('cdp', []))
        idp_count = len(prefetch_cache.get('idp', []))
        mission_kpi_count = len(prefetch_cache.get('mission_kpi', []))
        ground_rule_count = len(prefetch_cache.get('ground_rule', []))
        
        # ë°ì´í„° ìš”ì•½ í‘œì‹œ
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("Snippet", f"{archive_count}ê°œ")
        with col2:
            st.metric("CDP", f"{cdp_count}ê°œ")
        with col3:
            st.metric("IDP", f"{idp_count}ê°œ")
        with col4:
            st.metric("Mission & KPI", f"{mission_kpi_count}ê°œ")
        with col5:
            st.metric("Ground Rule", f"{ground_rule_count}ê°œ")
        
        progress_placeholder.progress(0.7)
        status_placeholder.info("ğŸ¤– ì½”ì¹­ í”¼ë“œë°± ìƒì„± ì¤‘...")
        progress_placeholder.progress(0.8)
    
    # ìƒíƒœ í‘œì‹œ ì œê±°
    status_placeholder.empty()
    progress_placeholder.empty()
    
    st.markdown("---")
    
    # ì„±ê³¼ ì½”ì¹­ í”¼ë“œë°± (ìë™ ìƒì„±) - ì ‘ì´ì‹ ì¹´ë“œ
    render_performance_feedback_auto()
    
    st.markdown("<br>", unsafe_allow_html=True)  # ì¹´ë“œ ê°„ ê°„ê²©
    
    # ì„±ì¥ ì½”ì¹­ í”¼ë“œë°± (ìë™ ìƒì„±) - ì ‘ì´ì‹ ì¹´ë“œ
    render_growth_feedback_auto()

def main():
    """ë…ë¦½ ì‹¤í–‰ìš© ë©”ì¸ í•¨ìˆ˜"""
    st.set_page_config(
        page_title="1on1 ì½”ì¹­",
        page_icon="ğŸ‘¥",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    render_oneon1_embedded()

if __name__ == "__main__":
    main()

